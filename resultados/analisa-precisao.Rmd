---
title: "Análise da precisão"
output:
  html_document:
    df_print: paged
---

```{r}
library(tidyverse)
library(here)
library(modelr)
library(broom)

theme_set(theme_bw())
```

## Os dados

```{r carrega}
reclamacoes_raw = read_csv(here("data/reclamacoes-raw/reclamacoes-raw.csv"))
avaliacoes_raw = read_csv(here("data/avaliacoes/avaliacoes-20180222.csv"))
sentimentos = read_csv(here("data/sentimentos/sentimento.csv"))

reclamacoes_raw = reclamacoes_raw %>% 
    mutate(id = 1:n(), 
           comprimento_reclamacao = str_length(reclamacao), 
           nome_orgao = str_split(link, "/") %>% map_chr(~ .[[5]]))
```

`reclamacoes_l` tem um formato long em vez de wide (explicado [aqui](https://sejdemyr.github.io/r-tutorials/basics/wide-and-long/)).

```{r junta}
avaliacoes = avaliacoes_raw %>% 
    group_by(id_reclamação) %>% 
    summarise(insatisfação = median(insatisfação), 
              avaliadores = n())

reclamacoes = reclamacoes_raw %>% 
    inner_join(avaliacoes, by = c("id" = "id_reclamação")) %>% 
    left_join(sentimentos, by = "id")

reclamacoes_l = reclamacoes %>%  
    select(-palavras_op30, -palavras_sent) %>% 
    gather(key = "lexico", 
           value = "polaridade", 
           sentimento_op30, sentimento_sent)

```

Converte polaridades para escala 0-5

Antes de converter, é importante saber alguns valores chaves para cada lexico, como o minimo, maximo e os quartis
```{r}
summary(reclamacoes)



min_op30 = min(reclamacoes$sentimento_op30)
max_op30 = max(reclamacoes$sentimento_op30)
first_quantile_op30 = quantile(reclamacoes$sentimento_op30, 0.25)
third_quantile_op30 = quantile(reclamacoes$sentimento_op30, 0.75)

min_sent = min(reclamacoes$sentimento_sent)
max_sent = max(reclamacoes$sentimento_sent)
first_quantile_sent = quantile(reclamacoes$sentimento_sent, 0.25)
third_quantile_sent = quantile(reclamacoes$sentimento_sent, 0.75)
```
Agora que temos mais dados, iremos atualizar a tabela reclamacoes

```{r}
# Tem que ver se isso vai servir pra alguma coisa
 reclamacoes = reclamacoes %>% 
     mutate(Min_op30 = min_op30, 
     Max_op30 = max_op30,
     Q1_op30 = first_quantile_op30,
     Q3_op30 = third_quantile_op30,
     )

 reclamacoes = reclamacoes %>% 
     mutate(Min_sent = min_sent,
     Max_sent = max_sent,
     Q1_sent = first_quantile_sent,
     Q3_sent = third_quantile_sent
     )
     
```



Agora Iremos calcular a polaridade_normalizada1 usando a estrategia mais simples

```{r}
# tentar com ifelse

 polarizeResult1 <- function(Min, Max){
     range = Max - Min
     arr = (reclamacoes_l$polaridade - Min)/range
     normalized = 5 - ((arr*5) -0)
     return(normalized)
 }
 reclamacoes_l$polaridade_normalizada1 <-        ifelse(reclamacoes_l$lexico=="sentimento_op30",polarizeResult1(min_op30, max_op30), polarizeResult1(min_sent, max_sent))

     
```


Como os resultados dos lexicos possuem muitos valores extremos, criaremos a polaridade_normalizada2 que ao invés de considerar os minimos e maximos, considera os primeiros e terceiros quartis.

```{r}

polarizeResult2 <- function(Min, Max){
     range = Max - Min
     arr = (reclamacoes_l$polaridade - Min)/range
     normalized = 5 - ((arr*5) -0)
     normalized <- ifelse(arr<0, 5, normalized)
     normalized <- ifelse(arr>1, 0, normalized)
     return(normalized)
 }
 reclamacoes_l$polaridade_normalizada2 <-        ifelse(reclamacoes_l$lexico=="sentimento_op30",polarizeResult2(first_quantile_op30, third_quantile_op30), polarizeResult1(first_quantile_sent, third_quantile_sent))
     
```


Calcula o erro por reclamação

```{r}
reclamacoes_l = reclamacoes_l %>% 
    mutate(erro = (insatisfação - polaridade_normalizada1)**2)
```


## EDA

Inicial. Faça os gráficos a mais que achar necessário para entender os dados que temos de resultado.

```{r}
reclamacoes %>% 
    ggplot(aes(x = sentimento_op30, y = sentimento_sent)) + 
    geom_abline(slope = 1, intercept = 0, color = "grey") + 
    geom_count(alpha = .7) 
```

```{r}
reclamacoes_l %>% 
    ggplot(aes(x = insatisfação, y = polaridade_normalizada, group = insatisfação)) + 
    geom_jitter(alpha = .7)  + 
    facet_wrap(~ lexico)

reclamacoes_l %>% 
    ggplot(aes(x = insatisfação, y = erro, group = insatisfação)) + 
    geom_jitter(alpha = .5)  +
    # geom_boxplo() + 
    facet_wrap(~ lexico)
```


## Há relação entre o léxico e a precisão/erro?

Agora um modelo para responder sua pergunta.

```{r}
model_erro_lex = lm(erro ~ factor(lexico), data=reclamacoes_l)
tidy(model_erro_lex, conf.int = TRUE, conf.level = 0.95)
```
```{r}
glance(model_erro_lex)
```


#### Pelos resultados do p.value, cujo alpha está bem acima de 0.05, e do intervalo de confiança, que inclue 0, não parece haver relação entre o léxico e o erro. 

```{r}
reclamacoes_l = reclamacoes_l %>% # Adicionando predições do modelo ao dataframe
    add_predictions(model_erro_lex)
```

```{r}
reclamacoes_l %>%
    ggplot(aes(x = lexico)) +
    geom_line(aes(y = pred), colour = "red") +
    geom_point(aes(y = erro)) +
    labs(y = "Erro da predição")
    
```

**Dica** - o texto de resultado que queremos produzir é algo como: 

Regressão múltipla foi utilizada para analisar se VarIndep1 e VarIndep2 tem uma associação significativa com o erro na estimativa de instatisfação da reclemação. Os resultados da regressão indicam que um modelo com os 2 preditores no formato Erro = XXX.VarIndep1 + YYY.VarIndep2 explicam XX,XX% da variância da variável de resposta (R2 = XX,XX). VarIndep1, medida como/em [unidade ou o que é o 0 e o que é 1] tem uma relação significativa com o erro (b = [yy,yy;  zz,zz], IC com 95%), assim como VarIndep2 medida como [unidade ou o que é o 0 e o que é 1] (b = [yy,yy;  zz,zz], IC com 95%). O aumento de 1 unidade de VarIndep1 produz uma mudança de...

