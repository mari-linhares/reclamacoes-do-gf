---
title: "Análise da precisão"
output:
  html_document:
    df_print: paged
---

```{r}
library(tidyverse)
library(here)
library(modelr)
library(broom)

theme_set(theme_bw())
```

O governo recebe um grande número de reclamações e poderia gerenciar melhor seus recursos se soubesse o quão insatisfeitas as pessoas estão em relação a um certo órgão. Existem métodos para análise de sentimento aplicáveis, mas não sabemos se esses métodos são eficazes neste contexto. 

## Pergunta

Quão eficazes são métodos de análise de sentimento baseados em léxicos para estimar a insatisfação manifestada em reclamações recebidas pelo governo federal 

## Carregando os dados

```{r carrega}
reclamacoes_raw = read_csv(here("data/reclamacoes-raw/reclamacoes-raw.csv"))
avaliacoes_raw = read_csv(here("data/avaliacoes/avaliacoes-20180222.csv"))
sentimentos = read_csv(here("data/sentimentos/sentimento.csv"))
# sentimentos_ponderados = read_csv(here("data/sentimentos/sentimento_ponderado.csv"))

# adicionando id a reclamacoes, comprimento da reclamacao e nome do orgao
reclamacoes_raw = reclamacoes_raw %>% 
    mutate(id = 1:n(), 
           comprimento_reclamacao = str_length(reclamacao), 
           nome_orgao = str_split(link, "/") %>% map_chr(~ .[[5]]))
```

`reclamacoes_l` tem um formato long em vez de wide (explicado [aqui](https://sejdemyr.github.io/r-tutorials/basics/wide-and-long/)).

```{r junta}
avaliacoes = avaliacoes_raw %>% 
    group_by(id_reclamação) %>% 
    summarise(insatisfação = median(insatisfação), 
              avaliadores = n())

reclamacoes = reclamacoes_raw %>% 
    inner_join(avaliacoes, by = c("id" = "id_reclamação")) %>% 
    left_join(sentimentos, by = "id")

reclamacoes_l = reclamacoes %>%  
    # select(-palavras_op30, -palavras_sent) %>% 
    gather(key = "lexico", 
           value = "polaridade", 
           sentimento_op30, sentimento_sent)
```

Removendo reclamações em que pelo menos um dos léxicos não reconhece nenhuma palavra.

```{r}
reclamacoes_l = subset(reclamacoes_l, palavras_op30>0 & palavras_sent>0)
reclamacoes = subset(reclamacoes, palavras_op30>0 & palavras_sent>0)
```

## Converte polaridades para escala 0-5

Antes de converter é importante saber alguns valores chaves para cada léxico, como o mínimo, máximo e os quartis.

```{r}
summary(reclamacoes)

min_op30 = min(reclamacoes$sentimento_op30)
max_op30 = max(reclamacoes$sentimento_op30)
first_quantile_op30 = quantile(reclamacoes$sentimento_op30, 0.25, na.rm=T)
third_quantile_op30 = quantile(reclamacoes$sentimento_op30, 0.75, na.rm=T)

min_sent = min(reclamacoes$sentimento_sent)
max_sent = max(reclamacoes$sentimento_sent)
first_quantile_sent = quantile(reclamacoes$sentimento_sent, 0.25, na.rm=T)
third_quantile_sent = quantile(reclamacoes$sentimento_sent, 0.75, na.rm=T)
```

### Normalizando da maneira usual entre 0 e 5.

Agora iremos calcular a polaridade_normalizada_usal usando a estratégia mais simples, normalizando os valores entre 0 e 5 de maneira usual.

```{r}
 polarizeResultUsual <- function(Min, Max){
     range = Max - Min
     arr = (reclamacoes_l$polaridade - Min)/range
     normalized = 5 - ((arr*5) -0)  # invertendo 0-> 5 e 5->0
     return(normalized)
 }

# reclamacoes long
reclamacoes_l$polaridade_normalizada_usual <-        ifelse(reclamacoes_l$lexico=="sentimento_op30", polarizeResultUsual(min_op30, max_op30), polarizeResultUsual(min_sent, max_sent))

# reclamacoes op30
polarizeResultUsual2 <- function(Min, Max){
     range = Max - Min
     arr = (reclamacoes$sentimento_op30 - Min)/range
     normalized = 5 - ((arr*5) -0)  # invertendo 0-> 5 e 5->0
     return(normalized)
 }
reclamacoes$sentimento_op30_usual <- polarizeResultUsual2(min_op30, max_op30)

# reclamacoes sent
polarizeResultUsual3 <- function(Min, Max){
     range = Max - Min
     arr = (reclamacoes$sentimento_sent - Min)/range
     normalized = 5 - ((arr*5) -0)  # invertendo 0-> 5 e 5->0
     return(normalized)
 }
reclamacoes$sentimento_sent_usual <- polarizeResultUsual3(min_sent, max_sent)
```

### Normalizando utilizando os quartis

Como os resultados dos léxicos possuem muitos valores extremos, criaremos a polaridade_normalizada_quartil que ao invés de considerar os mínimos e máximos, considera os primeiros e terceiros quartis.

```{r}
polarizeResultQuartil <- function(Min, Max){
     range = Max - Min
     arr = (reclamacoes_l$polaridade - Min)/range
     normalized = 5 - ((arr*5) -0)
     normalized <- ifelse(arr<0, 5, normalized)
     normalized <- ifelse(arr>1, 0, normalized)
     return(normalized)
 }

# reclamacoes long
reclamacoes_l$polaridade_normalizada_quartil <-        ifelse(reclamacoes_l$lexico=="sentimento_op30", polarizeResultQuartil(first_quantile_op30, third_quantile_op30), polarizeResultQuartil(first_quantile_sent, third_quantile_sent))

# reclamacoes op30
polarizeResultQuartil2 <- function(Min, Max){
     range = Max - Min
     arr = (reclamacoes$sentimento_op30 - Min)/range
     normalized = 5 - ((arr*5) -0)
     normalized <- ifelse(arr<0, 5, normalized)
     normalized <- ifelse(arr>1, 0, normalized)
     return(normalized)
 }

reclamacoes$sentimento_op30_quartil <- polarizeResultQuartil2(first_quantile_op30, third_quantile_op30)

# reclamacoes sent
polarizeResultQuartil3 <- function(Min, Max){
     range = Max - Min
     arr = (reclamacoes$sentimento_sent - Min)/range
     normalized = 5 - ((arr*5) -0)
     normalized <- ifelse(arr<0, 5, normalized)
     normalized <- ifelse(arr>1, 0, normalized)
     return(normalized)
 }

reclamacoes$sentimento_sent_quartil <- polarizeResultQuartil3(first_quantile_sent, third_quantile_sent)
```

## Calculando o erro por reclamação

```{r}
reclamacoes_l = reclamacoes_l %>%
    mutate(erro_usual = (insatisfação - polaridade_normalizada_usual)**2,
           erro_quartil = (insatisfação - polaridade_normalizada_quartil)**2)
```

## EDA - Verificando os resultados

### Comparando os valores dos léxicos

```{r}
reclamacoes %>% 
    ggplot(aes(x = sentimento_op30, y = sentimento_sent)) + 
    geom_abline(slope = 1, intercept = 0, color = "grey") + 
    geom_count(alpha = .7) 
```

### Comparando os valores dos léxicos normalizados

#### Normalização usual

```{r}
reclamacoes %>% 
    ggplot(aes(x = sentimento_op30_usual, y = sentimento_sent_usual)) + 
    geom_abline(slope = 1, intercept = 0, color = "grey") + 
    geom_count(alpha = .7) 
```

### Normalização utilizando os quartis

```{r}
reclamacoes %>% 
    ggplot(aes(x = sentimento_op30_quartil, y = sentimento_sent_quartil)) + 
    geom_abline(slope = 1, intercept = 0, color = "grey") + 
    geom_count(alpha = .7) 
```

### Erro e comparação das normalizações

### Usual

```{r}
reclamacoes_l %>% 
    ggplot(aes(x = insatisfação, y = polaridade_normalizada_usual, group = insatisfação)) + 
    geom_jitter(alpha = .7)  + 
    facet_wrap(~ lexico)

reclamacoes_l %>% 
    ggplot(aes(x = insatisfação, y = erro_usual, group = insatisfação)) + 
    geom_jitter(alpha = .5)  +
    # geom_boxplo() + 
    facet_wrap(~ lexico)
```

### Quartil

```{r}
reclamacoes_l %>% 
    ggplot(aes(x = insatisfação, y = polaridade_normalizada_quartil, group = insatisfação)) + 
    geom_jitter(alpha = .7)  + 
    facet_wrap(~ lexico)

reclamacoes_l %>% 
    ggplot(aes(x = insatisfação, y = erro_quartil, group = insatisfação)) + 
    geom_jitter(alpha = .5)  +
    # geom_boxplo() + 
    facet_wrap(~ lexico)
```

## Há relação entre o léxico e a precisão/erro?

Aqui iremos construir vários modelos buscando entender a relação entre o léxico (e outras variáveis independentes) e o erro.

### Considerando apenas o léxico

```{r}
model_erro_lex = lm(erro_usual ~ factor(lexico), data=reclamacoes_l)
tidy(model_erro_lex, conf.int = TRUE, conf.level = 0.95)
glance(model_erro_lex)
```

Pelos resultados do p.value, cujo alpha está bem acima de 0.05, e do intervalo de confiança, que inclue 0, não parece haver relação entre o léxico e o erro. 

### Considerando o léxico e o número de palavras

```{r}
model_erro_lex = lm(erro_usual ~ factor(lexico) + palavras, data=reclamacoes_l)
tidy(model_erro_lex, conf.int = TRUE, conf.level = 0.95)
```
```{r}
glance(model_erro_lex)
```

Regressão múltipla foi utilizada para analisar se o léxico e o número de palavras têm uma associação significativa com o erro na estimativa de instatisfação da reclamação. Os resultados da regressão indicam que um modelo com os preditores no formato Erro = X1.léxico + X2.palavras explicam ~18% da variância da variável de resposta (R² = 0.1793).
  
  * léxico: medida como fator (0 ou 1) tem uma relação não significativa com o erro (b = [-0.616199478	0.340265738], IC com 95%). Não podemos afirmar se um léxico é "melhor" que o outro para estes dados usando este modelo.
  * palavras: medida como unidade tem uma relação significativa com o erro (b = [0.003588207;	0.005864052], IC com 95%). Adicionar mais uma palavra ao texto faz com que o erro cresça ligeiramente, mais especificamente cerca de 0.005.

### Considerando o léxico, o número de palavras e o órgão

```{r}
model_erro_lex = lm(erro_usual ~ factor(lexico) + palavras + factor(nome_orgao), data=reclamacoes_l)
tidy(model_erro_lex, conf.int = TRUE, conf.level = 0.95)
```
```{r}
glance(model_erro_lex)
```

Regressão múltipla foi utilizada para analisar se o léxico, o número de palavras e o órgão têm uma associação significativa com o erro na estimativa de instatisfação da reclamação. Os resultados da regressão indicam que um modelo com os preditores no formato Erro = X1.léxico + X2.palavras + X3.órgão1 + X4.órgão2 + ... + XN.órgãoN explicam ~26% da variância da variável de resposta (R² = 0.2638).
  
  * léxico: medida como fator (0 ou 1) tem uma relação não significativa com o erro (b = [-0.602515183;	0.326581443], IC com 95%). Não podemos afirmar se um léxico é "melhor" que o outro para estes dados usando este modelo.
  
  * palavras: medida como unidade tem uma relação significativa com o erro (b = [0.003598035; 0.006104555], IC com 95%). Adicionar mais uma palavra ao texto faz com que o erro cresça ligeiramente, mais especificamente cerca de 0.005.

  * órgãos: para cada órgão foi criada uma variável medida como fator (0 ou 1), como são muitas variáveis vamos comentar apenas as que tem relação significativa.
    * inss-ministerio-da-previdencia-social: tem uma relação significativa com o erro (b = [0.251654415; 3.477687808], IC com 95%). Ser uma reclamação relacionada ao inss produz uma mudança de ~1.84 no erro.
    * ministerio-da-saude: tem uma relação significativa com o erro (b = [1.203197276;	4.796453197], IC com 95%). Ser uma reclamação relacionada ao inss produz uma mudança de ~3 no erro.
    * ministerio-do-planejamento: tem uma relação significativa com o erro (b = [0.022871807;	3.102570180], IC com 95%). Ser uma reclamação relacionada ao inss produz uma mudança de ~1.56 no erro.
    * serpro-servico-federal-de-processamento-de-dados: tem uma relação significativa com o erro (b = [0.169012336;	3.337198225], IC com 95%). Ser uma reclamação relacionada ao inss produz uma mudança de ~1.75 no erro.
    
```{r}
lexico_op30 = filter(reclamacoes_l, lexico=="sentimento_op30")
model_erro_lex_adj_op30 = lm(erro_usual ~  quant_adj_op30 + palavras + palavras_op30, data=lexico_op30)
tidy(model_erro_lex_adj_op30, conf.int=T, conf.level=0.95)
```
```{r}
glance(model_erro_lex_adj_op30)
```
```{r}
lexico_sent = filter(reclamacoes_l, lexico=="sentimento_sent")
model_erro_lex_adj_sent = lm(erro_usual ~  quant_adj_op30 + palavras + palavras_sent, data=lexico_sent)
tidy(model_erro_lex_adj_sent, conf.int=T, conf.level=0.95)
```
```{r}
glance(model_erro_lex_adj_sent)
```
### Considerando o número de palavras, quantidade de palavras do léxico e quantidade de adjetivos do léxico

Como resultado dessa regressão temos que essa variáveis não parecem ter uma associação significativa no valor do erro, pois o medelo Erro = X1.quantidade_de_adj_do_lexico + X2.palavras + palavras_do_lexico.

#### Léxico op30
O resultado explica ~25.8% da variância da variável de resposta (R²=0.2580945).

*  palavras_do_lexico: o fato de haver uma palavra a mais ou a menos reconhecida pelo léxico não parece afetar o valor do erro (b = [-0.116825546, 0.12650747], IC com 95%).
*  quantidade_de_adj_do_lexico: também não parece influenciar no valor do erro (b = [-0.233012935, 0.06500904], IC com 95%).
*  palavras: medida como unidade novamente nessa regressão ainda vemos uma influência ainda maior no valor do erro, (b = [0.004532165, 0.02076506], IC com 95%). Nessa regressão temos que adicionar uma palavra faz com que o erro aumente ~0.012.


#### Léxico sent
O resultado explica ~25.6% da variância da variável de resposta (R² = 0.2568307)

* palavras_do_lexico: diferentemente dos resultados do léxico op30, a quantidade de palavras do léxico sent parece alterar o valor do erro (b = [-0.4593449105, -0.086640290], IC com 95%). Temos que a cada palavra a mais que o léxico reconhece o valor do erro deve diminuir por volta de ~0.273.
* quantidade_de_adj_do_lexico: em contra partida ao resultado positivo (redução do erro do léxico) na utilização da variável independente palavras_do_lexico, tempo que a adição de um adjetivo que o léxico reconhece aumenta ligeiramente o valor do erro (por volta de ~0.433, sendo b = [0.2057182644, 0.660030044], IC com 95%).
* palavras: a quantidade de palavras da reclamação parece ter um impacto inferior comparado ao resultado obtido na regressão do léxico op30 (b = [0.0001938856, 0.006323553], IC com 95%), aumentando o valor do erro em ~0.0032.
```{r}
reclamacoes_l = reclamacoes_l %>% # Adicionando predições do modelo ao dataframe
    add_predictions(model_erro_lex)
```

```{r}
reclamacoes_l %>%
    ggplot(aes(x = lexico)) +
    geom_line(aes(y = pred), colour = "red") +
    geom_point(aes(y = erro_usual)) +
    labs(y = "Erro da predição") 
    
```
